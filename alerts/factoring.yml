groups:
  ###########################################################################
  # Factoring, more examples https://awesome-prometheus-alerts.grep.to/rules
  ###########################################################################
  - name: factoring
    rules:
      - alert: factoringPodNotHealthy
        expr: min_over_time ( sum (kube_pod_status_phase {namespace =~ "^Rrr-bla-bla phase=~"Pending|Unknown|Failed" } ) by (namespace, pod) [15m:30s] ) > 0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: Kubernetes Pod not healthy (instance {{ $labels.instance }})
          description: "Pod has been in a non-ready state for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          dashboard: "https://grafana.bank.rrr.vip-clients:3000/d/6_3W2ju7k/openshift-pod-info?var-origin_prometheus=OCP4%20PROD&var-Namespace=Rrr-bla-bla

      - alert: factoringPodRestarts
        expr: increase ( kube_pod_container_status_restarts_total {namespace =~ "^Rrr-bla-bla [10m] ) > 3
        for: 30s
        labels:
          severity: high
        annotations:
          summary: "Pod {{ $labels.pod }} restarts more than 3 times in the last 10 minutes"
          description: "Pod {{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          dashboard: "https://grafana.bank.rrr.vip-clients:3000/d/6_3W2ju7k/openshift-pod-info?var-origin_prometheus=OCP4%20PROD&var-Namespace=Rrr-bla-bla

      - alert: factoringDeploymentReplicasMismatch
        expr: kube_deployment_spec_replicas {namespace =~ "^Rrr-bla-bla != kube_deployment_status_replicas_available {namespace =~ "^Rrr-bla-bla
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: Kubernetes Deployment replicas mismatch (instance {{ $labels.instance }})
          description: "Deployment Replicas mismatch\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          dashboard: "https://grafana.bank.rrr.vip-clients:3000/d/6_3W2ju7k/openshift-pod-info?var-origin_prometheus=OCP4%20PROD&var-Namespace=Rrr-bla-bla

      - alert: factoringPodMemoryLimitUsage
        expr: ( sum ( container_memory_working_set_bytes {namespace =~ "^Rrr-bla-bla container = ""} ) by (origin_prometheus, namespace, pod) / sum ( kube_pod_container_resource_limits_memory_bytes { namespace =~ "^Rrr-bla-bla }) by (origin_prometheus, namespace, pod) ) > 0.9
        for: 30s
        labels:
          severity: warning
        annotations:
          summary: "Pod {{ $labels.pod }} uses more than 90% limit of memory"
          description: "Container Memory usage is above 90%\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          dashboard: "https://grafana.bank.rrr.vip-clients:3000/d/6_3W2ju7k/openshift-pod-info?var-origin_prometheus=OCP4%20PROD&var-Namespace=Rrr-bla-bla

      - alert: factoringContainerOomKiller
        expr: ( kube_pod_container_status_restarts_total {namespace =~ "^Rrr-bla-bla - kube_pod_container_status_restarts_total {namespace =~ "^Rrr-bla-bla offset 10m >= 1) and ignoring (reason) min_over_time ( kube_pod_container_status_last_terminated_reason {namespace =~ "^Rrr-bla-bla reason="OOMKilled"}[10m]) == 1
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: Kubernetes container oom killer (instance {{ $labels.instance }})
          description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
